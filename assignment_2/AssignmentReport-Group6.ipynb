{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "<img src=\"handwritten_1a_1.png\" width=\"700\" />\n",
    "<img src=\"handwritten_1a_2.png\" width=\"700\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n",
    "<img src=\"handwritten_1b.png\" width=\"700\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2c)\n",
    "![](task2c_train_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2d)\n",
    "\n",
    "The neural network has 784 input nodes + 1 for the bias trick, 64 hidden nodes and 10 outputs nodes. The input layer does not have weights/bias so we only calculate parameters for the hidden and outputs layers. All layers are fully connected.\n",
    "\n",
    "Hidden layer:\n",
    "64 * 785 = 50240\n",
    "\n",
    "Output layer:\n",
    "10 * 64 = 640\n",
    "\n",
    "For a total of 50240 + 640 = 50880 parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see on the plot each improvement step also improves the model's loss/accuracy.\n",
    "\n",
    "Weight initalization results in earlier stopping and this combined with the improved sigmoid funcion results in even earlier stopping. The same happens when we add momentum, resulting in a third of the original training time.\n",
    "\n",
    "The green model has a steep learning curve in the beginning which quickly flattens out. This can be a sign of a too high learning rate for that particular case.\n",
    "\n",
    "Momentum does seem to be a good solution to this problem. As the paper mentiones \"*Momentum can increase speed when the cost surface is highly nonspherical because it damps the size og the step along directions of high curvature thus yielding a larger effective learning rate along the directions of low curvature.*\", which seems to be just the case for this problem. The reduced learning rate when using momentum also seemed to be a good idea.\n",
    "\n",
    "Nevertheless, we can see that when using only weight initalization we actually got the best final validation accuracy, although it needed a lot of time to train. The momentum model could have gotten a better accuracy if it were given more time to train, although risking overfitting if it was given the opportunity.\n",
    "\n",
    "![](task3_loss.png)\n",
    "\n",
    "All models also have higher validation accuracy than training accuracy, which can be a sign of overfitting as the model does not work that good on new unseen data, although a final accuracy of around 0.96 is good.\n",
    "\n",
    "![](task3_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "\n",
    "**\\[785, 32, 10\\] neurons in the network (including the input layer)**\n",
    "\n",
    "With 32 nodes in the hidden layer the model performs better than the original model with 64 nodes. The original model had a final validation loss and validation accuracy of around 0.3 and 0.91, while the 32 node model has a final validation loss and validation accuracy of around 0.21 and 0.94.\n",
    "\n",
    "\n",
    "\n",
    "![](task4a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "\n",
    "**\\[785, 128, 10\\] neurons in the network (including the input layer)**\n",
    "\n",
    "This model with 128 nodes in the hidden layer performs even better than the model with 32 nodes. This model has a final validation loss and validation accuracy of around 0.15 and 0.96.\n",
    "\n",
    "Although this model has increased accuracy it has also an incrased training time. The 32-node model early stopped at epoch 25, while this 128-node model early stopped at epoch 29.\n",
    "\n",
    "![](task4b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4d)\n",
    "\n",
    "<img src=\"handwritten_4c.png\" width=\"700\" />\n",
    "\n",
    "As we can see, by reducing the first hidden layer from 64 nodes to 60 nodes, we can actually add a whole new hidden layer with 60 nodes and still keep the parameter count about the same.\n",
    "\n",
    "As we can see ...\n",
    "\n",
    "![](task4d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4e)\n",
    "\n",
    "By increasing the number of hidden layers to 10 we see that the model performs MUCH worse. Barely making any progress in loss/accuracy. The reason for this is that the gradients decline quickly in very deep network architectures. The backpropagation errors become smaller and smaller after each layer, resulting in very slow learning.\n",
    "\n",
    "![](task4e.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('py38': conda)",
   "language": "python",
   "name": "python38164bitpy38condac1f68ca5407a4349b0d7e37676f2fbb3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}