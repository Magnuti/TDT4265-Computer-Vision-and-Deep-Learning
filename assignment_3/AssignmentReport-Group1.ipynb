{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "This solution is taken from my solution to task 1f) in image processing assingment 1 in TDT4195 previous semester, as the task was identical to this task. I chose to handle borders with **same padding**, becasue the output dimension should be equal to the input dimension. Furthermore, the padding is a **clip filter** as the padding consists of only zeros. This was the simplest to implement.\n",
    "\n",
    "![](task1_a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n",
    "The convolutional layer, as it does not care about the feature's position.\n",
    "\n",
    "## task 1c)\n",
    "\n",
    "2 on each side.\n",
    "\n",
    "![](task1_c.png)\n",
    "\n",
    "## task 1d)\n",
    "\n",
    "For a sqaure image, with a square filter we have:\n",
    "\n",
    "$outputDim = (inputDim - filterDim + 2 * padding) / stride + 1$  \n",
    "$(outputDim - 1) * stride = inputDim - filterDim + 2 * padding$  \n",
    "$(outputDim - 1) * stride - inputDim- 2 * padding = -filterDim$  \n",
    "$filterDim = -((outputDim - 1) * stride - inputDim - 2 * padding)$  \n",
    "$filterDim = -(outputDim - 1) * stride + inputDim + 2 * padding)$  \n",
    "$filterDim = -(504 - 1) * 1 + 2 * 0 + 512)$  \n",
    "$filterDim = - 503 + 512 = 9$\n",
    "\n",
    "Thus, each kernel is $9x9$.\n",
    "\n",
    "## task 1e)\n",
    "\n",
    "If we perform pooling/subsampling with a 2x2 kernel on a 504x504 layer with a stride of 2, we will simply half the image's height and width, because each 2x2 pixel-block will be reduced to a single pixel. Thus, the output, after the pooling layer, is 252x252.\n",
    "\n",
    "## task 1f)\n",
    "\n",
    "$outputDim = (252 - 3 + 2 * 0) / 1 + 1 = 249 + 0 + 1 = 250$\n",
    "\n",
    "Thus, the output dimension is 250x250.\n",
    "\n",
    "## task 1g)\n",
    "\n",
    "A square-filter convolutional layer has $F^2*inputChannels*outputChannels+outputChannels$ parameters, where bias is also given by $outputChannels$.\n",
    "\n",
    "Layer 1: $5^2*3*32+32=2,432$  \n",
    "Layer 2: $5^2*32*64+64=51,264$  \n",
    "Layer 3: $5^2*64*128+128=204,928$  \n",
    "\n",
    "Now, we need to find the input dimension to the fully connected network. After three 2x2 max-pooling operations with a stride of 2, and an input image of 32x32, we get $32/2^3=4$. We have 128 such images (i.e., channels). Thus, the FCNN has an input dimension of $4^2*128$\n",
    "\n",
    "Layer 4: $4^2*128*64+64=131,136$  \n",
    "Layer 5: $64*10+10=650$  \n",
    "\n",
    "For a total of $2,432+51,264+204,928+131,136+650=390,410$ parameters in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "### Task 2a)\n",
    "\n",
    "![](plots/task2_plot.png)\n",
    "\n",
    "### Task 2b)\n",
    "\n",
    "Training Loss: 0.49  \n",
    "Validation Loss: 0.85  \n",
    "Testing Loss: 0.87  \n",
    "\n",
    "Training Accuracy: 0.830  \n",
    "Validation Accuracy: 0.712  \n",
    "Testing Accuracy: 0.719  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a)\n",
    "### Task 3b)\n",
    "### Task 3c)\n",
    "### Task 3d)\n",
    "### Task 3e)\n",
    "### Task 3f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "\n",
    "Training Loss: 0.03  \n",
    "Validation Loss: 0.30  \n",
    "Testing Loss: 0.35  \n",
    "\n",
    "Training Accuracy: 0.989  \n",
    "Validation Accuracy: 0.907  \n",
    "Testing Accuracy: 0.901\n",
    "\n",
    "![](task4a_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "\n",
    "Original image:\n",
    "\n",
    "![](images/zebra.jpg)\n",
    "\n",
    "The five activations and weights explained:  \n",
    "1. This filter looks like a vertical edge-detection filter. We see that the Zebra's vertical stripes are clear, while the horizontal line between the sky and the grass (blue-green) is nearly gone.  The weights looks like the vertical Sobel-operator, which confirms this.  \n",
    "2. This filter looks like a horizontal edge-detection filter as the sky-grass line and the zebra's horizontal lines are visible, while the vertical lines are more faded. The weights looks like the horizontal Sobel-operator, which confirms this.  \n",
    "3. This filter is used to detect blue values, as the sky is lit. We can see that the blue weights are highly represented.  \n",
    "4. This filter looks something like the Laplacian of Gaussian filter but only for left-diagonal edge detection. We see that the zebra's left-diagonal edges are visible, while the right-diagonal edges are blurred out. This applies especially for high contrast edges such as black-white-edges.  \n",
    "5. This filter is used to detect green values, as the grass is lit. We can see that the green weights are highly represented.  \n",
    "\n",
    "\n",
    "![](plots/task4b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4c)\n",
    "\n",
    "Well, it is difficult to understand these deep activations. The earlier layers of a CNN works with low-level features (e.g., edge detection) as we can still see a zebra in the activations of the first layer. As we go deeper down the network, these features are abstracted away more and more as it tries to fit the important information into the classifier.\n",
    "\n",
    "Activations for the last layer in ResNet:\n",
    "\n",
    "![](plots/task4c.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('py38': conda)",
   "language": "python",
   "name": "python38164bitpy38condac1f68ca5407a4349b0d7e37676f2fbb3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}